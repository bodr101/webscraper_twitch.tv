{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4bc784",
   "metadata": {},
   "source": [
    "<b>Import packages & run Selenium</b>\n",
    "\n",
    "<i>Selenium</i> is used to run the webdriver and perform actions, such as scrolling, on the webdriver. <i>Time</i> is imported to set a sleeptime for the program to run, which stops the program for a predetermined period. <i>Datetime</i> is imported to give a specific timestamp to capture the time of collection for the scraper. <i>BeautifulSoup</i> is imported to find parse the HTML soup. <i>Re</i> is imported to adjust full streamer names to only the tags which can be used to make the URL of the twitch stream. <i>JSON </i> allows the scraper to store all of the data into a json file and <i>TQDM</i> helps visualizing the progress of the scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6383e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "from selenium.webdriver import ActionChains\n",
    "from bs4 import BeautifulSoup # Use beautifulsoup to parse the html soup\n",
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3790e59",
   "metadata": {},
   "source": [
    "# Chapter 1: Open Chromedriver and collecting categories \n",
    "\n",
    "<br>\n",
    "This part of the scraper contains code to start the chromedriver and scrape the top 30 categories on that moment that are livestreamed on https://www.twitch.tv/directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d57742",
   "metadata": {},
   "source": [
    "## 1.1 Run Chromedriver\n",
    "\n",
    "Here the chromedriver options are defined. The chromedriver is opened with default content settings to decrease loading time of the websites and the language of the chromedriver is set to english, to prevent category names to differ in different languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57265782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pepijn de Vries\\AppData\\Local\\Temp\\ipykernel_65484\\867641456.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=chrome_options)\n",
      "C:\\Users\\Pepijn de Vries\\AppData\\Local\\Temp\\ipykernel_65484\\867641456.py:6: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=chrome_options)\n"
     ]
    }
   ],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\n",
    "    #this will disable image loading\n",
    "    \"prefs\", {\"profile.managed_default_content_settings.images\": 2,'intl.accept_languages': 'en,en_US'}\n",
    ")\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=chrome_options)\n",
    "\n",
    "url = \"https://www.twitch.tv/directory?sort=VIEWER_COUNT\"       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8711d1",
   "metadata": {},
   "source": [
    "## 1.2 Collecting Category names\n",
    "<br>\n",
    "In this code snippet the driver is opened on the browse page where all of the categories are listed. After opening up the driver page, the names of the categories are collected and put into a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec308be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the URL in maximized window\n",
    "driver.maximize_window();\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "soup=BeautifulSoup(driver.page_source)\n",
    "categories = soup.find_all('h2', class_ = \"CoreText-sc-cpl358-0 fzONq\")\n",
    "category_list = []\n",
    "for category in categories:\n",
    "    category = category.get_text()\n",
    "    category = category.replace(' ','%20')\n",
    "    category = category.replace(':', '%3A')\n",
    "    category_list.append(category)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76284fce",
   "metadata": {},
   "source": [
    "# Chapter 2: Generating a list of streamer names\n",
    "<br>\n",
    "The following function takes a category from <b>category_list</b> and opens the category website. The driver will then start scrolling untill the minimum number of viewers(which is predetermined) is reached. When the driver arrives at the minimum number of viewers, it will stop scrolling. <i>BeautifulSoup</i> will transform the HTML data to readable text and all of the streamer names will be collected and put into a list <b>streamer_name</b>. When the list <b>streamer_name</b> is compiled, the <i>get_twitch_data</i> function in the following chapter will go through all of the streamer names their 'about' pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad3cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streamer_data(category_list):\n",
    "    url = \"https://www.twitch.tv/directory/game/\" + category_list +\"?sort=VIEWER_COUNT\"\n",
    "    driver.get(url)\n",
    "    streamer_name = []\n",
    "    time.sleep(2)\n",
    "    # Here we create a variable check which indicates the while loop wheter to stop or not.\n",
    "    check = True\n",
    "    #Here you can fill in the minimum amount of viewers the streamer must have for the scroller to stop.\n",
    "    minimum = 50\n",
    "    # With this part we put the focus on an element on the page.\n",
    "    element = driver.find_element(By.XPATH, '//*[@id=\"directory-game-main-content\"]/div[1]/div[2]/div/div[2]/div[1]/h1')\n",
    "    action = ActionChains(driver)\n",
    "    action.move_to_element(to_element = element).click().perform()\n",
    "    #Here we create a scrolling function which stops at the minimum amount of viewers, mentioned above.\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    viewer_list = soup.find_all(class_ = \"ScMediaCardStatWrapper-sc-1ncw7wk-0 jluyAA tw-media-card-stat\")\n",
    "    print(\"Scrolling... (could take some time)\\n\")\n",
    "    while (check == True):\n",
    "        element2=driver.find_element(By.TAG_NAME,  'body')\n",
    "        element2.send_keys(Keys.END)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(driver.page_source)\n",
    "        viewer_list = soup.find_all(class_ = \"ScMediaCardStatWrapper-sc-1ncw7wk-0 jluyAA tw-media-card-stat\")\n",
    "        for item in viewer_list:\n",
    "            viewer_count = re.sub(r'[^0-9,.,K]', '', item.get_text())\n",
    "            if \"K\" in viewer_count:\n",
    "                viewer_count = re.sub(r'[^0-9,.,]', '',viewer_count)\n",
    "                double_check = int(float(viewer_count) * 1000)\n",
    "            else: \n",
    "                double_check = int(viewer_count)       \n",
    "            if (double_check< minimum):\n",
    "                    check = False\n",
    "    \n",
    "    print(\"Done Scrolling for streamers \\n\")\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #Reshape the categories to be printed as normal text.\n",
    "    category_list = category_list.replace('%20',' ')\n",
    "    category_list = category_list.replace('%3A', ':')\n",
    "    time.sleep(2)\n",
    "    #Collecting all of the streamer names that are loaded on the page and putting them into a list.\n",
    "    soup=BeautifulSoup(driver.page_source)\n",
    "    streamers = soup.find_all('p', class_ = \"CoreText-sc-cpl358-0 eyuUlK\")\n",
    "    for streamer in streamers:    \n",
    "        name = re.sub(r'[^a-zA-Z,_,0-9,(]', '', streamer.get_text())\n",
    "        name = name.split(\"(\")\n",
    "        try:\n",
    "            name = name[1]\n",
    "        except:\n",
    "            name = name[0]    \n",
    "        streamer_name.append(name)\n",
    "    #When the full list of streamer names is compiled, the function calls a different function to retreive all of the individual\n",
    "    #streamer information\n",
    "    for name in tqdm(streamer_name, desc =\"Getting streamers from the Category: \" + category_list, mininterval = 5):\n",
    "        get_twitch_data(name)\n",
    "    streamer_name.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab55b6b6",
   "metadata": {},
   "source": [
    "# Chapter 3: Collecting individual streamer information\n",
    "\n",
    "<b>In this part of the code, a function has been written which collects the datapoints for all of the individual streamers. The datapoints collected per streamer are:</b>\n",
    "1. Time of collection \n",
    "2. Name of the streamer\n",
    "3. Name of the category (if applicable)\n",
    "4. Name of the team of the streamer (if applicable)\n",
    "5. Amount of followers of the streamer\n",
    "6. Content block list, which includes every 'img' element from the 'about' page of the streamer\n",
    "7. Textual content block, which includes every textual element from the 'about' page of the streamer\n",
    "\n",
    "These datapoints are all appended to an empty list which is created at the start of the function, called: 'data'.\n",
    "\n",
    "The final part of the code, 'json.dumps', dumps the dictionary filled with datapoints into the json file at the last part of the code, where a twitch_data.json file is openend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50492e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function that gets the information of the streamer's about page\n",
    "def get_twitch_data(streamer_name):\n",
    "    data = []\n",
    "    url = \"https://twitch.tv/\" + streamer_name + \"/about\"\n",
    "    driver.get(url)\n",
    "    #We let the code sleep for two seconds, so it has time to load in the full page.\n",
    "    time.sleep(2)\n",
    "    soup=BeautifulSoup(driver.page_source)\n",
    "    now = datetime.now()\n",
    "    #This code collects the timestamp of collecting the data\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    # With this code we collect the name of the streamer\n",
    "    try: \n",
    "        name_streamer = soup.find(class_ = \"CoreText-sc-cpl358-0 ScTitleText-sc-1gsen4-0 cyfUN gasGNr tw-title\").get_text()\n",
    "    except:\n",
    "        name_streamer = streamer_name\n",
    "    # Printing the name of the category of the streamer\n",
    "    try:\n",
    "        category = soup.find(class_ = \"CoreText-sc-cpl358-0 ScTitleText-sc-1gsen4-0 iUOVlD gasGNr tw-title\").find_all('span')[1]\n",
    "        category = category.get_text()\n",
    "    #If a streamer is banned or stopped streaming between scraping their name from the category page \n",
    "    #and scraping their about page they will receive NA for category\n",
    "    except:\n",
    "        category = \"NA\"\n",
    "    # With this code we print the teamname if there is one, otherwise it will fill in \"NA\" for team name\n",
    "    try:\n",
    "        team_name = soup.find(class_ = \"CoreText-sc-cpl358-0 fIcpuT\").get_text()\n",
    "    except:\n",
    "        team_name = \"NA\"\n",
    "    \n",
    "    # With this code we collect the amount of followers the streamer has\n",
    "    try:\n",
    "        follower_count = soup.find(class_ = \"CoreText-sc-cpl358-0 gVjya\").get_text()\n",
    "    except:\n",
    "        pass\n",
    "    content_block = []\n",
    "    for link in soup.find_all('img', {'data-test-selector':\"image_test_selector\"}): \n",
    "        content_block.append(link['src'])\n",
    "    # With this code we collect the textual elements from the info page of a streamer    \n",
    "    textual_content_block = []\n",
    "    for el in soup.find_all(class_ = \"Layout-sc-nxg1ff-0 ScTypeset-sc-xkayed-0 iwcdTx fbdVqS tw-typeset\"):\n",
    "        textual_content_block.append(el.find_all(text=True))\n",
    "    # In this for loop we collect all the data from above and put it in a dictionary. Afterwards we dump this dictionary in a json-file\n",
    "    data.append({'Time of collection': dt_string,\n",
    "                'Name of the streamer': name_streamer,\n",
    "                'Category': category,\n",
    "                 'Team Name': team_name,\n",
    "                'Followers': follower_count,\n",
    "                'Content Block': content_block,\n",
    "                'Textual Content Block': textual_content_block})\n",
    "    for item in data:\n",
    "        f.write(json.dumps(item))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d37bb8",
   "metadata": {},
   "source": [
    "# Chapter 4: Write collected information to a .json file\n",
    "\n",
    "In the final part of the code, a .json file is opened called 'twitch_data.json'. The information is stored in this file through a for loop which iterates over the entire list of categories. Within this categories function, the get_streamer_data function is located, which scrapes data of each individual streamer. This is then written to the .json file and holds the variables as a dictionary. This dictionary full of datapoints is dumped into the 'twitch_data.json' file through the 'json.dumps' code in the 'get_streamer_data' function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a473e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrolling... (could take some time)\n",
      "\n",
      "Done Scrolling for streamers \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b51a63b4c0646f0aa2b8e4360609688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting streamers from the Category: Just Chatting:   0%|          | 0/664 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrolling... (could take some time)\n",
      "\n",
      "Done Scrolling for streamers \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e114bd229f2d4843ac9c934279bc72b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Getting streamers from the Category: Overwatch 2:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = open('twitch_data.json', 'w',encoding = 'utf-8')    \n",
    "for category in category_list:\n",
    "    get_streamer_data(category)\n",
    "f.close()\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
